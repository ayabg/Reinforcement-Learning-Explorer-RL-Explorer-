{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uAA2GNh4_w1I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0baff19a-f358-483e-8498-a3365de4cfc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 49900\n",
            "Saved q_table during training: 49900\n",
            "Training finished.\n",
            "[[-1.25       -1.25       -1.24999923 -1.25       -7.43749413 -7.1747276 ]\n",
            " [-1.24999423 -1.24999439 -1.24999441 -1.24999439 -1.24998925 -7.        ]\n",
            " [-1.2482698  -1.24824397 -1.24841796 -1.24824397 -1.24328    -7.        ]\n",
            " ...\n",
            " [-1.24092961 -1.23833243 -1.24092961 -1.24398207 -7.         -7.        ]\n",
            " [-1.24966003 -1.24968186 -1.24966003 -1.24968737 -7.         -7.        ]\n",
            " [-1.008      -1.008      -1.008       1.05       -7.         -7.        ]]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import gym\n",
        "import numpy as np\n",
        "import random\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import Markdown, display\n",
        "sys.tracebacklimit = 0\n",
        "def printmd(string):\n",
        "  display(Markdown(string))\n",
        "# Init Taxi-V2 Env\n",
        "env = gym.make(\"Taxi-v3\").env\n",
        "# Init arbitrary values\n",
        "q_table = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "# Hyperparameters+\n",
        "alpha = 0.7 # Momentum 0.2, Current 0.8 Greedy, 0.2 is to reduce volatility and flip flop\n",
        "gamma = 0.2 # Learning Rate 0.1 Greediness is 10%\n",
        "epsilon = 0.4 # explore 10% exploit 90%\n",
        "all_epochs = []\n",
        "all_penalties = []\n",
        "training_memory = []\n",
        "for i in range(1, 50000):\n",
        "  state = env.reset()\n",
        "  # Init Vars\n",
        "  epochs, penalties, reward, = 0, 0, 0\n",
        "  done = False\n",
        "  #training\n",
        "  while not done:\n",
        "    if random.uniform(0, 1) < epsilon:\n",
        "      # Check the action space\n",
        "      action = env.action_space.sample() # for explore\n",
        "    else:\n",
        "      # Check the learned values\n",
        "      action = np.argmax(q_table[state]) # for exploit\n",
        "      next_state, reward, done, info = env.step(action) #gym generate, the environment already setup for you\n",
        "      old_value = q_table[state, action]\n",
        "      next_max = np.max(q_table[next_state]) #take highest from q table for exploit\n",
        "      # Update the new value\n",
        "      new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
        "      q_table[state, action] = new_value\n",
        "      # penalty for performance evaluation\n",
        "    if reward == -10:\n",
        "      penalties += 1\n",
        "    state = next_state\n",
        "    epochs += 1\n",
        "  if i % 100 == 0:\n",
        "    training_memory.append(q_table.copy())\n",
        "    clear_output(wait=True)\n",
        "    print(\"Episode:\", i)\n",
        "    print(\"Saved q_table during training:\", i)\n",
        "print(\"Training finished.\")\n",
        "print(q_table)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# At state 499 i will definitely move west\n",
        "state = 499\n",
        "print(training_memory[0][state])\n",
        "print(training_memory[20][state])\n",
        "print(training_memory[50][state])\n",
        "print(training_memory[200][state])\n"
      ],
      "metadata": {
        "id": "shVFkh4cARfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76eafdbf-3d2b-410b-fa14-46df63c6f012"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.008 -1.008 -1.008  1.05  -7.    -7.   ]\n",
            "[-1.008 -1.008 -1.008  1.05  -7.    -7.   ]\n",
            "[-1.008 -1.008 -1.008  1.05  -7.    -7.   ]\n",
            "[-1.008 -1.008 -1.008  1.05  -7.    -7.   ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# At state 77 i will definitely move east\n",
        "state = 77\n",
        "print(training_memory[0][state])\n",
        "print(training_memory[20][state])\n",
        "print(training_memory[50][state])\n",
        "print(training_memory[200][state])"
      ],
      "metadata": {
        "id": "OembhVhIA72k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6a78a38-b3fb-4065-8461-2ec62ba20758"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.008      -1.008       2.96519943 -0.7        -7.         -7.        ]\n",
            "[-1.008     -1.008      2.9500003 -0.7       -7.        -7.       ]\n",
            "[-1.008 -1.008  2.95  -0.7   -7.    -7.   ]\n",
            "[-1.008 -1.008  2.95  -0.7   -7.    -7.   ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To show that at state 393, how the move evolved\n",
        "from IPython.display import Markdown, display\n",
        "def printmd(string):\n",
        "  display(Markdown(string))\n",
        "action_dict = {0: \"move south\"\n",
        ",1: \"move north\"\n",
        ",2: \"move east\"\n",
        ",3: \"move west\"\n",
        ",4: \"pickup passenger\"\n",
        ",5: \"dropoff passenger\"\n",
        "}\n",
        "\n",
        "ENV_STATE = env.reset()\n",
        "print(env.render(mode='ansi'))\n",
        "state_memory = [i[ENV_STATE] for i in training_memory]\n",
        "printmd(\"For state **{}**\".format(ENV_STATE))\n",
        "for step, i in enumerate(state_memory):\n",
        "  if step % 200==0:\n",
        "    choice = np.argmax(i)\n",
        "    printmd(\"for episode in {}, q table action is {} and it will ... **{}**\".format(step*100, choice, action_dict[choice]))\n",
        "    print(i)\n",
        "    print()"
      ],
      "metadata": {
        "id": "3pxkIfTPBPow",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "7f854904-442e-453d-da5e-751f099241ff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|R: | : :\u001b[34;1mG\u001b[0m|\n",
            "| : | : : |\n",
            "|\u001b[43m \u001b[0m: : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "For state **207**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "for episode in 0, q table action is 1 and it will ... **move north**"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.24985165 -1.24982745 -1.24989789 -1.24985041 -7.         -7.        ]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "for episode in 20000, q table action is 2 and it will ... **move east**"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.24999994 -1.24999994 -1.24999991 -1.24999996 -7.         -7.        ]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "for episode in 40000, q table action is 2 and it will ... **move east**"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.24999994 -1.24999994 -1.24999991 -1.24999996 -7.         -7.        ]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def print_frames(frames):\n",
        "  for i, frame in enumerate(frames):\n",
        "    clear_output(wait=True)\n",
        "    print(frame['frame'])\n",
        "    print(f\"Episode: {frame['episode']}\")\n",
        "    print(f\"Timestep: {i + 1}\")\n",
        "    print(f\"State: {frame['state']}\")\n",
        "    print(f\"Action: {frame['action']}\")\n",
        "    print(f\"Reward: {frame['reward']}\")\n",
        "    time.sleep(0.8)\n",
        "total_epochs, total_penalties = 0, 0\n",
        "episodes = 10 # Try 10 rounds\n",
        "frames = []\n",
        "for ep in range(episodes):\n",
        "  state = env.reset()\n",
        "  epochs, penalties, reward = 0, 0, 0\n",
        "  done = False\n",
        "  while not done:\n",
        "    action = np.argmax(q_table[state]) # deterministic (exploit), not stochastic (explore), only explore in training\n",
        "    env\n",
        "    state, reward, done, info = env.step(action) #gym\n",
        "    if reward == -10:\n",
        "      penalties += 1\n",
        "    # Put each rendered frame into dict for animation, gym generated\n",
        "    frames.append({\n",
        "        'frame': env.render(mode='ansi'),\n",
        "        'episode': ep,\n",
        "        'state': state,\n",
        "        'action': action,\n",
        "        'reward': reward})\n",
        "    epochs += 1\n",
        "  total_penalties += penalties\n",
        "  total_epochs += epochs\n",
        "print_frames(frames)\n",
        "print(f\"Results after {episodes} episodes:\")\n",
        "print(f\"Average timesteps per episode: {total_epochs / episodes}\")\n",
        "print(f\"Average penalties per episode: {total_penalties / episodes}\")"
      ],
      "metadata": {
        "id": "SQxt6V-0Cu9t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6da0cb7-3cf3-4826-eded-4dc79a884172"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|R: | : :\u001b[35m\u001b[34;1m\u001b[43mG\u001b[0m\u001b[0m\u001b[0m|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (Dropoff)\n",
            "\n",
            "Episode: 9\n",
            "Timestep: 137\n",
            "State: 85\n",
            "Action: 5\n",
            "Reward: 20\n",
            "Results after 10 episodes:\n",
            "Average timesteps per episode: 13.7\n",
            "Average penalties per episode: 0.0\n"
          ]
        }
      ]
    }
  ]
}